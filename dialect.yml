# Copyright 2021 Esri
#
# Licensed under the Apache License Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# 


# id of the connector type (mandatory)
id: sample.dialect


# id of the parent dialect. It allows your dialect to inherit all unconfigured properties from a parent dialect.
super class: esri.base

# configures how SQL identifiers will be generated, mandatory if super class is not defined.
# See page https://github.com/Esri/insights-connector-guide/wiki/Identifier-Setting for more details
identifier setting:
  escape character: '"'  
  characters to escape: \'
  open enquote: '"'
  close enquote: '"'
  maximum identifier length: 64
  table prefix: arcgis_insights_

# configures some important SQL clauses used in Insights. The template uses named variables in the format of ${namedVariable} to represent different parts.
# See page https://github.com/Esri/insights-connector-guide/wiki/SQL-Clauses for more details on how to configure this section
sql clauses:
  select constant: SELECT ${columns}  
  limit: SELECT * FROM (${source}) t LIMIT ${limit} 
  pagination: SELECT * FROM (${source}) t ORDER BY ${orderby} LIMIT ${limit} OFFSET ${offset}
  column asc in order by: ${column} ASC
  column desc in order by: ${column} Desc
  alter table: ATLER TABLE ${name}
  add constraint: ADD CONSTRAINT
  create table: CREATE TABLE ${name} (${columns} ${primaryKeys})
  create table as: CREATE TABLE ${name} AS ${sql}
  drop table: DROP TABLE ${name}
  insert into: INSERT INTO ${name} (${columns}) VALUES ${values}
  create attribute index: CREATE INDEX ${index} ON ${table} (${columns})
  create spatial index: # no default configuration
  find extent: # no default configuration
  find geometry type: >
    SELECT CASE WHEN ST_DIMENSION(${shape}) = 0
           THEN CASE WHEN ST_NPOINTS(${shape}) = 1 THEN 0 ELSE 3 END
           ELSE ST_DIMENSION(${shape}) END as dimension
    FROM ${source}
    WHERE ${shape} IS NOT NULL
    LIMIT 1
  get spatial reference: SELECT ST_SRID(${shape}) FROM ${source} WHERE ${shape} IS NOT NULL LIMIT 1
  validate write permission to schema: #no default clause
  list schemas: # no default clause

# Configures the capabilities of the database. Default value is false.
# See page https://github.com/Esri/insights-connector-guide/wiki/SQL-Capabilities for more details on how to configure this section
sql capabilities:
  window functions: true
  window function in where clause: false
  common table expression: true
  named parameters in common table expression: true
  floating point numbers in partition by: true
  spatial support: true
  write back: true
  support primary key constraint: true
  support alphanuemric indexes: true
  support spatial indexes: true
  support join operation between numbers and strings: true
  support angular unit spatial reference systems: true
  requires schema in sql: true

# configures the sql syntax for window functions used in Insights. The template uses index-based placeholders, such as $0, $1 etc to represent different parameters
# See page https://github.com/Esri/insights-connector-guide/wiki/SQL-Functions for more details
window functions:
  # row number without partition
  # $0: comma separated order by names
  - name: row number
    sql: ROW_NUMBER() OVER(ORDER BY $0)

  # row number with partition
  # $0: comman separated names, $1: comma separated names
  - name: partitioned row number
    sql: ROW_NUMBER() OVER(PARTITION BY $0 ORDER BY $1)

  # average with partition
  # $0: name of the column to be averaged, $1: comma separated column names
  - name: average over
    sql: AVG($0) OVER(PARTITION BY $1)

  # sum with partition
  - name: sum over
    sql: SUM($0) OVER(PARTITION BY $1)
   
  # lag functon with offset 1
  - name: lag over
    sql: LAG($0) OVER(ORDER BY $1)

  # sliding average, or moving average without partition
  # $0: name of the column to be averaged, $1: comma separate names, $2 and $3: number that define the width of windows
  - name: sliding average
    sql: AVG($0) OVER(ORDER BY $1 ROWS BETWEEN $2 PRECEDING AND $3 following)

  # sliding average with partition
  # $0: name of the column to be averaged, $1 and $2: comma separate names, $3 and $4: number that define the width of windows
  - name: partitioned sliding average
    sql: AVG($0) OVER(PARTITION BY $1 ORDER BY $2 ROWS BETWEEN $3 PRECEDING AND $4 following)


# configures the most common SQL functions used in Insights.
# See page https://github.com/ArcGIS/insights-connector-guide/wiki/Configure-SQL-Functions for more details
sql functions:
  # aggregate functions group
  - name: count
    sql: COUNT($0)

  - name: count distinct
    sql: COUNT(DISTINCT $0)

  - name: sum
    sql: SUM($0)

  - name: avg
    sql: AVG($0)

  - name: max
    sql: MAX($0)

  - name: min
    sql: MIN($0)

  - name: stddev
    sql: STDDEV($0)

  - name: variance
    sql: VARIANCE($0)

  - name: median
    sql: MEDIAN($0)

  - name: mode
    sql: MODE($0)

  - name: percentile
    sql: PERCENTILE_CONT($0) WITHIN GROUP (ORDER BY $1)
  
  # string functions group
  - name: trim
    sql: TRIM(BOTH $0 FROM $1)

  - name: left trim
    sql: TRIM(LEADING $0 FROM $1)

  - name: right trim
    sql: TRIM(TRAILING $0 FROM $1)

  - name: lower
    sql: LOWER($0)

  - name: upper
    sql: UPPER($0)

  - name: string concatenation
    sql: CONCAT($0, $1)

  - name: string position
    sql: POSITION($0, $1, $2)

  - name: string length
    sql: LENGTH($0)

  - name: string substitute
    sql: REPLACE($0, $1, $2)

  - name: substring
    sql: SUBSTRING($0, $1, $2)

  - name: left
    sql: LEFT($0, $1)

  - name: right
    sql: RIGHT($0, $1)

  - name: like
    sql: $0 LIKE $1

  # date time functions group
  - name: extract year
    sql: DATEPART(year, $0)

  - name: extract quarter
    sql: DATEPART(quarter, $0)


  - name: extract month
    sql: DATEPART(month, $0)


  - name: extract day of month
    sql: DATEPART(day, $0)


  - name: extract day of week
    sql: DATEPART(weekday, $0)


  - name: extract hour
    sql: DATEPART(hour, $0)


  - name: extract minute
    sql: DATEPART(minute, $0)


  - name: extract second
    sql: DATEPART(second, $0)


  - name: datedif year
    sql: DATEDIFF(year, $0, $1)


  - name: datedif month
    sql: DATEDIFF(month, $0, $1)


  - name: datedif day
    sql: DATEDIFF(day, $0, $1)


  - name: datedif hour
    sql: DATEDIFF(hour, $0, $1)


  - name: datedif minute
    sql: DATEDIFF(minute, $0, $1)


  - name: datedif second
    sql: DATEDIFF(second, $0, $1)


  - name: create timestamp from milliseconds
    sql: to_timestamp($0/1000.0)

  - name: create timestamp from components
    sql: >
        TO_TIMESTAMP($0 || '-' || $1 || '-' || $2 || ' ' || $3 || ':' || $4 || ':' || $5,
              CASE WHEN length($0) > 2 THEN 'YYYY-MM-DD hh24:mi:ss' ELSE 'YY-MM-DD hh24:mi:ss' END)

  - name: create timestamp from text
    sql: TO_TIMESTAMP($0, '$1')


  - name: create time from milliseconds
    sql: TO_TIME($0/1000.0)


  - name: create time from components
    sql: >
      TO_TIME( $0 || ':' || $1 || ':' || $2, 'hh24:mi:ss')

  - name: create date from milliseconds
    sql: TO_DATE($0/1000.0)

  - name: create date from components
    sql: TO_DATE($0 || '-' || $1 || '-' ||$2, CASE WHEN length($0) > 2 THEN 'YYYY-MM-DD' ELSE 'YY-MM-DD' END) 

  - name: current timestamp
    sql: CURRENT_TIMESTAMP

  - name: current time
    sql: CURRENT_DATE

  - name: current date
    sql: CURRENT_DATE

  - name: now
    sql: NOW()

  # conditional functions group

  - name: case when else
    sql: CASE WHEN $0 THEN $1 ELSE $2 END
 
  - name: case when
    sql: CASE WHEN $0 THEN $1 END
  
  - name: is null
    sql: $0 IS NULL

  - name: is not null
    sql: $0 IS NOT NULL

  - name: nullif
    sql: nullif($0, $1)

  - name: coalesce
    sql: COALESCE($0, $1)

  # logical operators
  - name: and
    sql: $0 AND $1

  - name: or
    sql: $0 OR $1

  - name: between
    sql: $0 BETWEEN $1 AND $2

  - name: not
    sql: NOT($0)

  # arithmetic functions group
  - name: abs
    sql: ABS($0)

  - name: acos
    sql: ACOS($0)

  - name: asin
    sql: ASIN($0)

  - name: atan
    sql: ATAN($0)

  - name: sin
    sql: SIN($0)

  - name: sinh
    sql: SINH($0)

  - name: cos
    sql: COS($0)

  - name: cosh
    sql: COSH($0)

  - name: tan
    sql: TAN($0)

  - name: tanh
    sql: TANH($0)

  - name: ln
    sql: LN(NULLIF(CASE WHEN $0 <= 0 THEN NULL ELSE $0 END ,0))

  - name: log
    sql: LOG(nullif(CASE WHEN $1 <= 0 THEN NULL ELSE $1 END, 0), CASE WHEN $0 <= 1 THEN NULL ELSE $0 END)

  - name: log10
    sql: LOG10(CASE WHEN $0 <= 0 THEN NULL ELSE $0 END)

  - name: negation
    sql: -($0)

  - name: add
    sql: ($0) + ($1)

  - name: subtract
    sql: ($0) - ($1)

  - name: multiply
    sql: $0 * $1

  - name: divide
    sql: $0 / NULLIF($1,0)

  - name: power
    sql: POWER($0, $1)

  - name: mod
    sql: MOD($0, $1)

  - name: round
    sql: ROUND($0)

  - name: round to
    sql: ROUND($0, CAST($1 AS INT))
  
  - name: ceiling
    sql: CEILING($0)

  - name: floor
    sql: FLOOR($0)
  
  - name: sign
    sql: SIGN($0)

  - name: truncate
    sql: TRUNC($0, $1)

  # conversion functions
  - name: cast
    sql: CAST($0 AS $1)


# Configures the types used for casting and DDL, mandatory if super class is not defined
# See page https://github.com/Esri/insights-connector-guide/wiki/Column-Types for more details
column types:
  integer: integer
  bigint: bigint
  float: float
  fixed: decimal(38, 8)
  string: varchar(255)
  date: date
  timestamp: timestamp
  time: time
  geometry: geometry

# Configures the placeholders used in PreparedStatement for different data types 
# See https://github.com/Esri/insights-connector-guide/wiki/SQL-Placeholders for more details
sql placeholders:
  integer: '?'
  float: '?'
  fixed: '?'
  string: '?'
  date: '?'
  timestamp: '?'
  time: '?'
  geometry: '?'

# Configures the sql syntax for date and time formats, mandatory if section "date format codes" is not defined
# See page https://github.com/Esri/insights-connector-guide/wiki/String-Date-Conversion for more details
date and time sql tokens:
  YY: yy
  YYYY: yyyy
  MM: MM
  DD: dd
  hh: hh
  hh24: HH
  mi: mi
  ss: ss
  ms: ms
  mon: mon
  ampm: am

# Configures some shortcut for date and time format mapping 
# See page https://github.com/Esri/insights-connector-guide/wiki/String-Date-Conversion for more details
date format codes:
  # US
  "mm/dd/yy": mm/dd/yy
  "mm/dd/yyyy": mm/dd/yyyy
  # ANSI
  "yy.mm.dd": yy.mm.dd
  "yyyy.mm.dd": yyyy.mm.dd
  # British/French
  "dd/mm/yy": dd/mm/yy
  "dd/mm/yyyy": dd/mm/yyyy
  # German
  "dd.mm.yy": dd.mm.yy
  "dd.mm.yyyy": dd.mm.yyyy
  # Italian
  "dd-mm-yy": dd-mm-yy
  "dd-mm-yyyy": dd-mm-yyyy
  # Japan
  "yy/mm/dd": yy/mm/dd
  "yyyy/mm/dd": yyyy/mm/dd
  # ISO
  "yymmdd": yymmdd
  "yyyymmdd": yyyymmdd
  # month name
  "dd mon yy": dd mon yy
  "dd mon yyyy": dd mon yyyy
  "Mon dd, yy": mon dd, yy
  "Mon dd, yyyy": mon dd, yyyy

# Configures the state code for different types of sql exceptions. This section is optional, but it helps Insights displays correct error message.
# Some databases publish their error codes, for example Postgres: https://www.postgresql.org/docs/10/errcodes-appendix.html
# See page https://github.com/Esri/insights-connector-guide/wiki/SQL-Error-States for more details
sql error states:
  invalid datetime format: 22007
  datetime overflow: 22008
  query cancelled: 57014
  connection failed: 08001
  cannot connect now: 57P03
